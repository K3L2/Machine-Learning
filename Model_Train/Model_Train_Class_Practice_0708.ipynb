{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw1MHKib9G-z",
        "outputId": "45b0ded5-e03c-4ecb-eaa8-af595d420a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/PCB_QM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0VuwjJz9TMg",
        "outputId": "012613a3-17c9-4cee-f2e4-86576482f0e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/PCB_QM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('test_pickle.pickle','rb') as file :\n",
        "    pk_data = pickle.load(file)"
      ],
      "metadata": {
        "id": "BEVv2fmn9fJj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pk_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zO9T6n79omX",
        "outputId": "6707a425-b3cd-43c9-e274-6c13b4587cd4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['img_list', 'label_list'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "d7muoEZ7-B7h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization,Dropout"
      ],
      "metadata": {
        "id": "SqG_0m9dDyFB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "zK_LuKr8KcZ7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_Train:\n",
        "    def __init__(self, data_pickle,img_list_col='img_list',prod_col='product_type',error_col='error_type', random_seed = 42):\n",
        "        self.seed = random_seed\n",
        "        tf.set_random_seed(self.seed)\n",
        "        self.load_pickle(img_list_col,prod_col,error_col)\n",
        "\n",
        "    def load_pickle(self,pickle_path,img_list_col,prod_col,error_col):\n",
        "        with open(pickle_path,'rb') as file:\n",
        "            pk_data = pickle.load(file)\n",
        "            # pickle data를 numpy array 형태로 저장\n",
        "            self.image_set = np.array(pk_data[img_list_col])\n",
        "            self.prod_label_set = np.array(pk_data[prod_col])\n",
        "            self.error_label_set = np.array(pk_data[error_col])\n",
        "\n",
        "        self.img_shape = self.image_set[0].shape\n",
        "        self.error_label_num = len(np.unique(self.error_label_set))\n",
        "        self.class_dict = {v: k for k, v in enumerate(np.unique(self.error_label_set))}\n",
        "\n",
        "    def gen_train_test_set(self,test_rate = 0.1):\n",
        "        '''학습 및 테스트 데이터를 분류'''\n",
        "        self.error_img_train, self.error_img_test, self.error_label_train, self.error_label_test = train_test_split(self.image_set,self.error_label_set,\n",
        "                                                                                                  test_size = test_rate, random_state = self.seed,\n",
        "                                                                                                  stratify= self.error_label_set)\n",
        "\n",
        "    def model_generate(self,fliter_num:int = 32, conv_layer:int = 2, dense_unit:int = 128 , drop_rate:float = 0.2 ) :\n",
        "        '''모델 생성'''\n",
        "        # 모델 초기화\n",
        "        model = Sequential()\n",
        "\n",
        "        # 초기 레이어 생성\n",
        "        model.add(Conv2D(fliter_num, (3, 3), activation='relu', input_shape=self.img_shape))\n",
        "        model.add(Conv2D(fliter_num, (3, 3), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Dropout(drop_rate))\n",
        "\n",
        "        try :\n",
        "            # 레이어 추가\n",
        "            for i in range(1, conv_layer)\n",
        "                model.add(Conv2D(fliter_num * (i+1), (3, 3), activation='relu', input_shape=self.img_shape))\n",
        "                model.add(Conv2D(fliter_num * (i+1), (3, 3), activation='relu'))\n",
        "                model.add(BatchNormalization())\n",
        "                model.add(MaxPooling2D((2, 2)))\n",
        "                model.add(Dropout(drop_rate))\n",
        "        except Exception:\n",
        "            print('conv_laber에 2 이상 값을 넣어야 레이어 추가가 됩니다.')\n",
        "\n",
        "        # 전연결\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_unit, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(drop_rate))\n",
        "        model.add(Dense(self.error_label_num, activation='softmax'))\n",
        "\n",
        "        # 모델 요약 출력 (선택 사항)\n",
        "        model.summary()\n",
        "\n",
        "        model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def train_basic(self,test_rate = 0.1, batch_size = 16, epochs = 5):\n",
        "        '''테스트 데이터를 분류하고 에러 학습'''\n",
        "        self.gen_train_test_set(test_rate)\n",
        "        self.history = self.model.fit(self.error_train_img, self.error_label_train, batch_size = batch_size, epochs = epochs)\n",
        "        print(\"학습이 끝났습니다. history를 통해 학습 과정을 확인할 수 있습니다.\")\n",
        "\n",
        "    def validation(self):\n",
        "        '''테스트 데이터 정확도 확인'''\n",
        "        # 전체 정확도 평가\n",
        "        test_loss, test_accuracy = self.model.evaluate(self.error_test_img, self.error_label_test)\n",
        "        print(f'Test Accuracy: {test_accuracy:.2f}\\n\\n')\n",
        "\n",
        "        # 예측\n",
        "        y_pred = self.model.predict(self.error_test_img)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "        # 예측 결과와 원래 라벨 출력\n",
        "        predicted_labels = [self.class_dict[k] for k in y_pred_classes]\n",
        "\n",
        "        cnt = 0\n",
        "        for real_label, pred_label in zip(self.error_label_test, predicted_labels):\n",
        "            print(f\"index : {cnt} --- 정답 라벨 : {real_label} ---> 예측 라벨 : {pred_label}\")\n",
        "            cnt+=1\n"
      ],
      "metadata": {
        "id": "dC-trm6a9seV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}